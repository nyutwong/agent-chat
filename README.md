# AI Chat Agent

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô AI Agent ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ models ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á OpenAI (ChatGPT) ‡πÅ‡∏•‡∏∞ Ollama Providers ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à AI Agent ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö model ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ

## Features

- ü§ñ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á OpenAI ‡πÅ‡∏•‡∏∞ Ollama Provider
- üîÑ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏°‡∏ô‡∏π‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö
- üí¨ Chat interface ‡πÅ‡∏ö‡∏ö interactive
- üìä ‡πÅ‡∏™‡∏î‡∏á token usage (input/output tokens)
- üìù ‡πÄ‡∏Å‡πá‡∏ö conversation history
- üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á conversation history ‡πÑ‡∏î‡πâ
- ‚öôÔ∏è ‡∏Å‡∏≥‡∏´‡∏ô‡∏î system prompt ‡πÑ‡∏î‡πâ

## ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

1. ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies:
```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment
uv venv

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows
venv\Scripts\activate
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö macOS/Linux
source venv/bin/activate

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies
uv sync
```

2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API keys ‡πÅ‡∏•‡∏∞ configuration ‡πÑ‡∏ü‡∏•‡πå `.env` ‡∏à‡∏≤‡∏Å `.env.example`:
```
# OpenAI Configuration
OPENAI_API_KEY=

# Ollama Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL = scb10x/llama3.1-typhoon2-8b-instruct

#Model configuration
TEMPERATURE=0.7
SYSTEM_PROMPT="""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤ [‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏áagent]

‡∏â‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠ [‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì] ‡∏≠‡∏≤‡∏¢‡∏∏ [‡∏≠‡∏≤‡∏¢‡∏∏] ‡∏õ‡∏µ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô [‡∏≠‡∏≤‡∏ä‡∏µ‡∏û] ‡∏ó‡∏µ‡πà [‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£]
‡∏â‡∏±‡∏ô‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á [‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏ô‡πÉ‡∏à ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ, ‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô, ‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß] ‡πÅ‡∏•‡∏∞‡∏ä‡∏≠‡∏ö [‡∏á‡∏≤‡∏ô‡∏≠‡∏î‡∏¥‡πÄ‡∏£‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠, ‡πÄ‡∏•‡πà‡∏ô‡∏î‡∏ô‡∏ï‡∏£‡∏µ, ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ]
‡πÄ‡∏ß‡∏•‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
‡∏ñ‡πâ‡∏≤‡∏â‡∏±‡∏ô‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö [‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©] ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏â‡∏±‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏≠‡∏¢‡∏π‡πà
‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô‡∏ô‡∏∞!"""
```

3. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ollama ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama ‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ:
```bash
ollama pull llama3.1-8b-instruct
```

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°:
```bash
uv run python main.py
```

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:
1. AI provider (Ollama ‡∏´‡∏£‡∏∑‡∏≠ OpenAI)
2. Model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ default ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏©

- `quit` - ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
- `clear` - ‡∏•‡πâ‡∏≤‡∏á conversation history
- `history` - ‡∏î‡∏π conversation history

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Code

### OpenAI
```python
from models.openai import ChatGPTAgent

# ‡∏™‡∏£‡πâ‡∏≤‡∏á agent
agent = ChatGPTAgent(api_key="your_api_key", model="gpt-4o-mini")

# ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
response = agent.chat("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ")
print(response)
```

### Ollama
```python
from models.ollama import OllamaAgent

# ‡∏™‡∏£‡πâ‡∏≤‡∏á agent
agent = OllamaAgent(model="llama3.1-8b-instruct")

# ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏° system prompt
response = agent.chat(
    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á AI", 
    system_prompt="‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô AI"
)
print(response)
```

## Token Usage

‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á token usage ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API:
- Input tokens: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô tokens ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ
- Output tokens: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô tokens ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏±‡∏ö
- Total tokens: ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î