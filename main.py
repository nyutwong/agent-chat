import os
from dotenv import load_dotenv
from providers.openai import OpenAIAgent
from providers.ollama import OllamaAgent
from providers.langchain import LangchainAgent

load_dotenv()

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI Agent"""
    
    print("ü§ñ Agent Chat")
    print("=" * 50)
    
    # Ask for provider
    print("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å AI provider:")
    print("1. Ollama (default)")
    print("2. OpenAI")
    print("3. Langchain")
    provider_choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (1/2/3) [‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ default]: ").strip()
    
    # Set provider based on choice
    if provider_choice == "2":
        provider = "openai"
    elif provider_choice == "3":
        provider = "langchain"
    else:
        provider = "ollama"  # Default or if user pressed Enter or chose 1
    
    # Set default models based on provider
    if provider == "openai":
        default_model = os.getenv("OPENAI_MODEL")
        print(f"\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å OpenAI model (default: {default_model}):")
    
        model_name = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model [‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ default]: ").strip()
        if model_name =="":
            model_name=default_model
        
        agent = OpenAIAgent(api_key=os.getenv("OPENAI_API_KEY"), model=model_name)
        ai_name = "OpenAI"
    elif provider == "langchain":
        default_provider = os.getenv("LANGCHAIN_PROVIDER", "ollama")
        
        model_provider = input(f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model provider [ollama/openai] (default: {default_provider}): ").strip()
        if model_provider == "":
            model_provider = default_provider

        default_model = os.getenv("OLLAMA_MODEL", "scb10x/llama3.1-typhoon2-8b-instruct") if model_provider == "ollama" else os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        print(f"\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Langchain model (default: {default_model}):")
        model_name = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model [‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ default]: ").strip()
        if model_name == "":
            model_name = default_model
            
            
        agent = LangchainAgent(model=model_name, model_provider=model_provider)
        ai_name = "Langchain"
    else:  # ollama
        default_model = os.getenv("OLLAMA_MODEL")
        print(f"\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Ollama model (default: {default_model}):")

        model_name = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model [‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ default]: ").strip()
        if model_name =="":
            model_name=default_model
        
        agent = OllamaAgent(host=os.getenv("OLLAMA_HOST"), port=os.getenv("OLLAMA_PORT"), model=model_name)
        ai_name = "Ollama"
    
    if provider == "langchain":
        print(f"\nü§ñ AI Agent - Using {provider.upper()} with model: {model_name} (provider: {model_provider})")
    else:
        print(f"\nü§ñ AI Agent - Using {provider.upper()} with model: {model_name}")
    print("=" * 50)
    
    # System prompt
    system_prompt = os.getenv("SYSTEM_PROMPT")
    
    print("üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    print("üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå 'clear' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡πâ‡∏≤‡∏á conversation history")
    print("üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå 'history' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π conversation history")
    print("-" * 50)
    
    while True:
        try:
            # ‡∏£‡∏±‡∏ö input ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
            user_input = input("\nüßë‚Äçüíª ‡∏Ñ‡∏∏‡∏ì: ").strip()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏©
            if user_input.lower() == 'quit':
                print("üëã ‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô!")
                break
            elif user_input.lower() == 'clear':
                agent.clear_history()
                continue
            elif user_input.lower() == 'history':
                history = agent.get_history()
                print("\nüìù Conversation History:")
                for i, msg in enumerate(history, 1):
                    role = "üßë‚Äçüíª" if msg["role"] == "user" else "ü§ñ"
                    print(f"{i}. {role} {msg['role']}: {msg['content'][:100]}...")
                continue
            
            if not user_input:
                continue
                
            print(f"\nü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
            
            # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏´‡∏≤ AI
            response = agent.chat(user_input, system_prompt)
            
            if response:
                print(f"\nü§ñ {ai_name}: {response}")
            
        except KeyboardInterrupt:
            print("\n\nüëã ‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô!")
            break
        except Exception as e:
            print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

if __name__ == "__main__":
    main()